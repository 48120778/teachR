conmat <- function(predicted, expected){
cm <- as.matrix(table(Actual = as.factor(expected$class), Predicted = predicted))
cm
}
f1_score <- function(predicted, expected, positive.class="1") {
cm = conmat(predicted, expected)
precision <- diag(cm) / colSums(cm)
recall <- diag(cm) / rowSums(cm)
f1 <-  ifelse(precision + recall == 0, 0, 2 * precision * recall / (precision + recall))
#Assuming that F1 is zero when it's not possible compute it
f1[is.na(f1)] <- 0
#Binary F1 or Multi-class macro-averaged F1
ifelse(nlevels(expected) == 2, f1[positive.class], mean(f1))
}
accuracy <- function(predicted, expected){
cm <- confusionMatrix(predicted, expected)
sum(diag(cm)/length(test$class))
}
cm <- conmat(predicted, expected)
accuracy <- function(predicted, expected){
cm <- conmat(predicted, expected)
sum(diag(cm)/length(test$class))
}
f1_score(test_pred, test$class)
f1_score(test_pred, test$class)
f1_score(test_pred, test)
get_scores <- function(predictions, test){
f1 <- f1_score(predictions,test)
acc <- accuracy(predictions,test)
scores <- c(accuracy = acc, f1 = f1)
scores
}
pander(get_scores(test_pred, test))
conmat <- function(predicted, expected){
cm <- as.matrix(table(Actual = as.factor(expected$class), Predicted = predicted))
cm
}
f1_score <- function(predicted, expected, positive.class="1") {
cm = conmat(predicted, expected)
precision <- diag(cm) / colSums(cm)
recall <- diag(cm) / rowSums(cm)
f1 <-  ifelse(precision + recall == 0, 0, 2 * precision * recall / (precision + recall))
#Assuming that F1 is zero when it's not possible compute it
f1[is.na(f1)] <- 0
#Binary F1 or Multi-class macro-averaged F1
ifelse(nlevels(expected) == 2, f1[positive.class], mean(f1))
}
accuracy <- function(predicted, expected){
cm <- conmat(predicted, expected)
sum(diag(cm)/length(test$class))
}
get_scores <- function(predictions, test){
f1 <- f1_score(predictions,test)
acc <- accuracy(predictions,test)
scores <- c(accuracy = acc, f1 = f1)
scores
}
pander(get_scores(test_pred, test))
nb_fit <- train(training,
training$class,
trControl = trainMethod,
method = "nb",
tuneLength = 10
)
nb_fit <- train(training,
training$class,
trControl = trainMethod,
method = "nb",
tuneLength = 10
)
```
nb_fit <- train(training,
training$class,
trControl = trainMethod,
method = "nb",
tuneLength = 10
)
nb_fit
plot(nb_fit)
nb_pred <- predict(nb_fit, test)
nb_pred <- predict(nb_fit, newdata = test)
nb_pred
confusionMatrix(nb_pred, test$class)
get_scores(nb_pred, test)
fastNaiveBayes.detect_distribution(x, nrows = nrow(x))
y <- train$class
x <- train[-1]
y <- trainng$class
x <- training[-1]
y <- training$class
x <- training[-1]
fastNaiveBayes.detect_distribution(x, nrows = nrow(x))
dist <- fastNaiveBayes.detect_distribution(x, nrows = nrow(x))
dist
fast_nb_fit <- fastNaiveBayes.mixed(x,y)
fast_nb_fit
summary(fast_nb_fit)
plot(fast_nb_fit)
fast_pred <- predict(fast_nb_fit, test[-1])
fast_pred
confusionMatrix(fast_pred, test$class)
get_scores(fast_pred, test)
confusionMatrix(fast_pred, test$class)
get_scores(fast_pred, test)
library(caret)
library(fastNaiveBayes)
library(readr)
library(functional)
library(ggplot2)
library(magrittr)
library(doParallel)
library(caret)
library(fastNaiveBayes)
library(readr)
library(functional)
library(ggplot2)
library(magrittr)
library(caret)
library(fastNaiveBayes)
library(readr)
library(functional)
library(ggplot2)
library(magrittr)
dataurl <- "https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data"
wine <- read_csv(dataurl, col_names = F)
good_cols <- c("class",
"alcohol",
'malic_acid',
'ash',
'alkalinity',
'magnesium',
'total_phenols',
'flavanoids',
'nonflavonoids_phenols',
'proanthocyanins',
'color_intensity',
'hue',
'dilution',
'proline'
)
fix_cols <- function(df){
colnames(df) <- good_cols
df$class <- as.factor(df$class)
df
}
wine <- fix_cols(wine)
wine
set.seed(3033)
## WARNING: Danger function
split <- function(df, p = 0.75, list = FALSE, ...) {
train_ind <- createDataPartition(df[[1]], p = p, list = list)
cat("creating training dataset...\n")
training <<- df[train_ind, ]
cat("completed training dataset, creating test set\n")
test <<- df[-train_ind, ]
cat("done")
}
split(wine)
library(doParallel)
numcores <- parallel::detectCores() -1
cl <- makePSOCKcluster(numcores)
registerDoParallel(cl)
set.seed(3333)
trainMethod <- trainControl(method = "repeatedcv",
number = 10,
repeats = 3)
knn_fit <- train(class ~ .,
data = training,
method = "knn",
trControl = trainMethod,
preProcess = c("center", "scale"),
tuneLength = 10)
library(pander)
knn_fit
plot(knn_fit)
knn_fit2 <- knn3(training, training$class, k = 15)
knn_fit2
test_pred <- predict(knn_fit, newdata = test)
test_pred
confusionMatrix(test_pred, test$class)
conmat <- function(predicted, expected){
cm <- as.matrix(table(Actual = as.factor(expected$class), Predicted = predicted))
cm
}
f1_score <- function(predicted, expected, positive.class="1") {
cm = conmat(predicted, expected)
precision <- diag(cm) / colSums(cm)
recall <- diag(cm) / rowSums(cm)
f1 <-  ifelse(precision + recall == 0, 0, 2 * precision * recall / (precision + recall))
#Assuming that F1 is zero when it's not possible compute it
f1[is.na(f1)] <- 0
#Binary F1 or Multi-class macro-averaged F1
ifelse(nlevels(expected) == 2, f1[positive.class], mean(f1))
}
accuracy <- function(predicted, expected){
cm <- conmat(predicted, expected)
sum(diag(cm)/length(test$class))
}
get_scores <- function(predictions, test){
f1 <- f1_score(predictions,test)
acc <- accuracy(predictions,test)
scores <- c(accuracy = acc, f1 = f1)
scores
}
pander(get_scores(test_pred, test))
nb_fit <- train(training,
training$class,
trControl = trainMethod,
method = "nb",
tuneLength = 10
)
nb_fit
plot(nb_fit)
nb_pred <- predict(nb_fit, newdata = test)
nb_pred
confusionMatrix(nb_pred, test$class)
get_scores(nb_pred, test)
y <- training$class
x <- training[-1]
dist <- fastNaiveBayes.detect_distribution(x, nrows = nrow(x))
dist
fast_nb_fit <- fastNaiveBayes.mixed(x,y)
fast_nb_fit
summary(fast_nb_fit)
fast_pred <- predict(fast_nb_fit, test[-1])
fast_pred
confusionMatrix(fast_pred, test$class)
get_scores(fast_pred, test)
nb_fit <- train(training,
training$class,
trControl = trainMethod,
method = "naivebayes",
tuneLength = 10
)
nb_fit <- train(training,
training$class,
trControl = trainMethod,
method = "naive_bayes",
tuneLength = 10
)
nb_fit
plot(nb_fit)
nb_pred <- predict(nb_fit, newdata = test)
nb_pred
confusionMatrix(nb_pred, test$class)
get_scores(nb_pred, test)
rm(list = ls())
library(caret)
library(fastNaiveBayes)
library(readr)
library(functional)
library(ggplot2)
library(magrittr)
dataurl <- "https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data"
wine <- read_csv(dataurl, col_names = F)
wine
good_cols <- c("class",
"alcohol",
'malic_acid',
'ash',
'alkalinity',
'magnesium',
'total_phenols',
'flavanoids',
'nonflavonoids_phenols',
'proanthocyanins',
'color_intensity',
'hue',
'dilution',
'proline'
)
fix_cols <- function(df){
colnames(df) <- good_cols
df$class <- as.factor(df$class)
df
}
wine <- fix_cols(wine)
wine
set.seed(3033)
## WARNING: Danger function
split <- function(df, p = 0.75, list = FALSE, ...) {
train_ind <- createDataPartition(df[[1]], p = p, list = list)
cat("creating training dataset...\n")
training <- df[train_ind, ]
cat("completed training dataset, creating test set\n")
test <- df[-train_ind, ]
cat("done")
}
split(wine)
x = 2
plus1 <- function() {
x =4
x
}
plus1
plus1()
x
plus1 <- function() {
x <<- 4
x
}
plus1()
x
set.seed(3033)
## WARNING: Danger function
split <- function(df, p = 0.75, list = FALSE, ...) {
train_ind <- createDataPartition(df[[1]], p = p, list = list)
cat("creating training dataset...\n")
training <- df[train_ind, ]
cat("completed training dataset, creating test set\n")
test <- df[-train_ind, ]
cat("done")
}
split(wine)
set.seed(3033)
## WARNING: Danger function
split <- function(df, p = 0.75, list = FALSE, ...) {
train_ind <- createDataPartition(df[[1]], p = p, list = list)
cat("creating training dataset...\n")
training <<- df[train_ind, ]
cat("completed training dataset, creating test set\n")
test <<- df[-train_ind, ]
cat("done")
}
split(wine)
square <- function(var){
x = x^2
x
}
z = 4
square(z)
zsquared <- square(z)
zsquared
## WARNING: Danger function
split <- function(df, p = 0.75, list = FALSE, ...) {
train_ind <- createDataPartition(df[[1]], p = p, list = list)
cat("creating training dataset...\n")
training <<- df[train_ind, ]
cat("completed training dataset, creating test set\n")
test <<- df[-train_ind, ]
cat("done")
}
split(wine)
library(doParallel)
parallel::detectCores()
numcores <- parallel::detectCores() - 1
cl <- makePSOCKcluster(numcores)
registerDoParallel(cl)
set.seed(3333)
set.seed(3333)
trainMethod <- trainControl(method = "repeatedcv",
number = 10,
repeats = 3)
# k-folds cross validation
# y ~ x
knn_fit <- train(class ~ .,
data = training,
method = "knn",
trControl = trainMethod,
preProcess = c("center", "scale"),
tuneLength = 10)
knn_fit
plot(knn_fit)
set.seed(3333)
trainMethod <- trainControl(method = "repeatedcv",
number = 10,
repeats = 3)
# k-folds cross validation
# y ~ x
knn_fit <- train(class ~ .,
data = training,
method = "knn",
trControl = trainMethod,
preProcess = c("center", "scale"),
tuneLength = 10)
knn_fit
set.seed(3033)
## WARNING: Danger function
split <- function(df, p = 0.75, list = FALSE, ...) {
train_ind <- createDataPartition(df[[1]], p = p, list = list)
cat("creating training dataset...\n")
training <<- df[train_ind, ]
cat("completed training dataset, creating test set\n")
test <<- df[-train_ind, ]
cat("done")
}
split(wine)
set.seed(3333)
trainMethod <- trainControl(method = "repeatedcv",
number = 10,
repeats = 3)
# k-folds cross validation
# y ~ x
knn_fit <- train(class ~ .,
data = training,
method = "knn",
trControl = trainMethod,
preProcess = c("center", "scale"),
tuneLength = 10)
knn_fit
plot(knn_fit)
knn_fit2 <- knn3(training, training$class, k = 15)
knn_fit2
test_pred <- predict(knn_fit, newdata = test)
test_pred
test_pred2 <- predict(knn_fit2, newdata = test)
test_pred2
confusionMatrix(test_pred, test$class)
confusionMatrix(test_pred2, test$class)
knn_fit2 <- knn3(training, training$class, k = 15, prob = FALSE)
knn_fit2
test_pred2 <- predict(knn_fit2, newdata = test)
test_pred2
test_pred2 <- predict(knn_fit2, newdata = test, prob = F)
test_pred2
confusionMatrix(test_pred2, test$class)
confusionMatrix(test_pred, test$class)
conmat <- function(predicted, expected){
cm <- as.matrix(table(Actual = as.factor(expected$class), Predicted = predicted))
cm
}
f1_score <- function(predicted, expected, positive.class="1") {
cm = conmat(predicted, expected)
precision <- diag(cm) / colSums(cm)
recall <- diag(cm) / rowSums(cm)
f1 <-  ifelse(precision + recall == 0, 0, 2 * precision * recall / (precision + recall))
#Assuming that F1 is zero when it's not possible compute it
f1[is.na(f1)] <- 0
#Binary F1 or Multi-class macro-averaged F1
ifelse(nlevels(expected) == 2, f1[positive.class], mean(f1))
}
accuracy <- function(predicted, expected){
cm <- conmat(predicted, expected)
sum(diag(cm)/length(test$class))
}
get_scores <- function(predictions, test){
f1 <- f1_score(predictions,test)
acc <- accuracy(predictions,test)
scores <- c(accuracy = acc, f1 = f1)
scores
}
pander(get_scores(test_pred, test))
conmat(test_pred, test)
conmat <- function(predicted, expected){
cm <- as.matrix(table(Actual = as.factor(expected$class), Predicted = predicted))
cm
}
conmat(test_pred, test)
f1_score <- function(predicted, expected, positive.class="1") {
cm = conmat(predicted, expected)
precision <- diag(cm) / colSums(cm)
recall <- diag(cm) / rowSums(cm)
f1 <-  ifelse(precision + recall == 0, 0, 2 * precision * recall / (precision + recall))
#Assuming that F1 is zero when it's not possible compute it
f1[is.na(f1)] <- 0
#Binary F1 or Multi-class macro-averaged F1
ifelse(nlevels(expected) == 2, f1[positive.class], mean(f1))
}
accuracy <- function(predicted, expected){
cm <- conmat(predicted, expected)
sum(diag(cm)/length(test$class))
}
get_scores <- function(predictions, test){
f1 <- f1_score(predictions,test)
acc <- accuracy(predictions,test)
scores <- c(accuracy = acc, f1 = f1)
scores
}
pander(get_scores(test_pred, test))
nb_fit <- train(training,
training$class,
trControl = trainMethod,
method = "naive_bayes",
tuneLength = 10
)
nb_fit
plot(nb_fit)
nb_fit <- train(training,
training$class,
trControl = trainMethod,
method = "naive_bayes",
tuneLength = 10
)
nb_fit
plot(nb_fit)
nb_fit <- train(training,
training$class,
trControl = trainMethod,
method = "nb",
tuneLength = 10
)
nb_fit
plot(nb_fit)
nb_pred <- predict(nb_fit, newdata = test)
nb_pred
confusionMatrix(nb_pred, test$class)
get_scores(nb_pred, test)
library(fastNaiveBayes)
y <- training$class
x <- training[-1]
dist <- fastNaiveBayes.detect_distribution(x, nrows = nrow(x))
dist
fast_nb_fit <- fastNaiveBayes.mixed(x,y)
fast_nb_fit
fast_pred <- predict(fast_nb_fit, test[-1])
fast_pred
fast_pred <- predict(fast_nb_fit, newdata = test)
fast_pred <- predict(fast_nb_fit, newdata = test[-1])
fast_pred
confusionMatrix(fast_pred, test$class)
get_scores(fast_pred, test)
stopCluster(cl)
